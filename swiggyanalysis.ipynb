{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Ob26P_jVWIT"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from ipywidgets import interact, widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "-6Qa4h8MXbp9",
    "outputId": "03494eb5-d230-48ce-f576-4c9efc65d4fc"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\susha\\Downloads\\archive\\swiggy.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9_wIMN63ZnUe",
    "outputId": "0fc72500-ae66-4a48-cbc5-93422c71f4d0"
   },
   "outputs": [],
   "source": [
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "rSnWQ6CReWbD",
    "outputId": "4c187b91-817d-4e34-ad94-55acbeac38f3"
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qaLZ7csAZHea",
    "outputId": "bc3f656c-b4eb-4908-c92e-f98e722dd2be"
   },
   "outputs": [],
   "source": [
    "# Unique restaurants\n",
    "unique_restaurant = df['Restaurant'].nunique()\n",
    "unique_restaurant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 489
    },
    "id": "LoTQ_tUDee9T",
    "outputId": "10b21d1f-5e2a-4df6-ab77-11e4e0dfea54"
   },
   "outputs": [],
   "source": [
    "# display all cuisines\n",
    "cuisines = df['Food type'].str.split(',').explode().str.strip()\n",
    "number_of_cuisines = cuisines.value_counts()\n",
    "number_of_cuisines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 397
    },
    "id": "adTCS-PyfOMQ",
    "outputId": "1eed524c-3a57-4410-b948-41d9864caeb5"
   },
   "outputs": [],
   "source": [
    "# Number of restaurants per cities\n",
    "num_per_city = df.groupby('City')['City'].count()\n",
    "num_per_city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "-TX5AHtOhPn8",
    "outputId": "fcf67e20-18e4-4c90-b771-161d5dfcd0a0"
   },
   "outputs": [],
   "source": [
    "num_per_city.idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "sPMmIE3SiBZw",
    "outputId": "c5109f31-3182-480a-eb87-dea25766d13d"
   },
   "outputs": [],
   "source": [
    "# Highest rated restaurant\n",
    "\n",
    "rest_by_rating = df.sort_values(by='Avg ratings', ascending=False)\n",
    "rest_by_rating[['Restaurant','City','Avg ratings']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 331
    },
    "id": "nKWRCq3ljFPz",
    "outputId": "52b2b9ed-c23e-4d8c-9e6f-f404f60c8b20"
   },
   "outputs": [],
   "source": [
    "# Cost of two person across cities\n",
    "city_wise = df.groupby('City')['Price'].mean().reset_index()\n",
    "city_wise\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 520
    },
    "id": "yqgVb0SVl9mb",
    "outputId": "52871a21-f2b9-4f9c-92c1-90f181de9c84"
   },
   "outputs": [],
   "source": [
    "X_city = city_wise['City']\n",
    "y_price = city_wise['Price']*2\n",
    "\n",
    "plt.figure()\n",
    "plt.grid()\n",
    "plt.plot(X_city, y_price)\n",
    "plt.scatter(X_city, y_price, c='red')\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel('City')\n",
    "plt.ylabel('Price for 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "HzMR0PuDnc7x",
    "outputId": "8dd86f4a-2f0f-41ad-ddd9-c244f88a451c"
   },
   "outputs": [],
   "source": [
    "# For interactive plot using plotly as px (hovering, zooming)\n",
    "city_wise_sorted = city_wise.sort_values(by='City')\n",
    "fig = px.line(city_wise_sorted, x='City', y='Price', title='Cost of 2 per city', labels={'City': 'City', 'Price': 'Price'}, markers=True)\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "OQM2asLMpmwx",
    "outputId": "6bdd759b-9b62-4dbd-e306-b52fad03fe4c"
   },
   "outputs": [],
   "source": [
    "# Distribution of restaurant ratings\n",
    "ratings = df['Avg ratings']\n",
    "plt.hist(ratings, bins=30, color='green', edgecolor='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 466
    },
    "id": "oMM-gxz4xH4-",
    "outputId": "1a99325f-a9fe-4be6-c91d-cf62d6320f47"
   },
   "outputs": [],
   "source": [
    "sns.histplot(data=df, x='Avg ratings', bins=30, kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 475
    },
    "id": "zobkinEx7Mtg",
    "outputId": "cf406dad-bce7-4d54-c02d-146989389445"
   },
   "outputs": [],
   "source": [
    "pr = df.sort_values(by='Price')\n",
    "pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "lhfy6PkXxi6f",
    "outputId": "4523ea9e-1b44-4f3a-a915-9ef624aa659b"
   },
   "outputs": [],
   "source": [
    "# Correlation between Price and rating\n",
    "plt.scatter(df['Price'], df['Avg ratings'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 435
    },
    "id": "8yux0dO2zZ_t",
    "outputId": "69bb78e0-c51a-40f1-c105-7365811e319d"
   },
   "outputs": [],
   "source": [
    "corr_mat = df[['Price','Avg ratings']].corr()\n",
    "\n",
    "sns.heatmap(corr_mat, annot=True, cmap='coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZdUReyrv_siB"
   },
   "outputs": [],
   "source": [
    "# Common cuisines in top rated restaurants\n",
    "# cuisine_rating = df1.groupby('Cuisines')['Avg ratings'].mean().sort_values(ascending=False).head(20).reset_index()\n",
    "# cuisine_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1o7qt7I7HZl4"
   },
   "outputs": [],
   "source": [
    "# df1 = df.copy()\n",
    "# df1['Cuisines'] = df1['Food type'].str.split(',')\n",
    "# df1 = df1.explode('Cuisines')\n",
    "# df1['Cuisines'] = df1['Cuisines'].str.strip().str.title()\n",
    "# df1\n",
    "# #df1.groupby('Cuisines')['Price'].mean().sort_values(ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 742
    },
    "id": "ezZ20jk7Iwos",
    "outputId": "70df86d0-1e42-4648-a2c0-611e51fe5cc0"
   },
   "outputs": [],
   "source": [
    "# Expensive cuisines\n",
    "import re\n",
    "\n",
    "df1 = df.copy()\n",
    "\n",
    "df1['Cuisines'] = df1['Food type'].str.split(r',|\\s{2,}')\n",
    "\n",
    "df1 = df1.explode('Cuisines')\n",
    "df1['Cuisines'] = df1['Cuisines'].str.strip().str.title()\n",
    "\n",
    "df1.groupby('Cuisines')['Price'].mean().sort_values(ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 742
    },
    "id": "GUNw8fb-OGnU",
    "outputId": "0b1aa25e-0b2b-43a1-a80c-78befdd0995e"
   },
   "outputs": [],
   "source": [
    "# Top rated Cuisines everywhere\n",
    "df1.groupby('Cuisines')['Avg ratings'].mean().sort_values(ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 676
    },
    "id": "UQXYwXxJO-5K",
    "outputId": "0e0cc76e-c2e2-4dbf-d4e5-b6186cf0ab46"
   },
   "outputs": [],
   "source": [
    "# Most common cuisines in top rated restaurants\n",
    "\n",
    "df_rating = df.sort_values(by='Avg ratings', ascending=False)\n",
    "df_rating[['Restaurant','Avg ratings','Food type']].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "0Ci_3AcJQl-f",
    "outputId": "f012f9da-04c1-4d72-807c-49a849c9ed13"
   },
   "outputs": [],
   "source": [
    "# Areas having the most restaurants\n",
    "df.groupby('Area')['Area'].count().idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "DpkkVdPg7X_8",
    "outputId": "d25a2935-7091-4706-e1ac-9f82d59850ff"
   },
   "outputs": [],
   "source": [
    "num_rest = df.groupby('Area')['Area'].count().reset_index(name='count')\n",
    "num_rest.sort_values(by='count', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 455
    },
    "id": "WiHH2GlZ8XPP",
    "outputId": "c22bb0c5-183b-479c-ce9a-29001a3d34cd"
   },
   "outputs": [],
   "source": [
    "# Average price andd rating by location\n",
    "avg_price_rating = df.groupby('Area')[['Price','Avg ratings']].mean()\n",
    "avg_price_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "6y4pKhut-Yc7",
    "outputId": "46e4705a-affe-459e-8d63-d7c71c693b6a"
   },
   "outputs": [],
   "source": [
    "# Check all the restaurants with price equals to zero\n",
    "df[df['Price']==0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m7Oc_os2_ijD"
   },
   "outputs": [],
   "source": [
    "# Since there are only 5 such entries, it is better to drop them\n",
    "df = df[df['Price'] !=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "9lvedT9nAvPy",
    "outputId": "f52a6ca2-77a1-40ad-f356-973c4fdc45e6"
   },
   "outputs": [],
   "source": [
    "# Visualization\n",
    "# Heatmap of average restaurant ratings by area\n",
    "avg_rating_by_area = df.groupby('Area')['Avg ratings'].mean().reset_index(name='Ratings')\n",
    "avg_rating_by_area\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 694
    },
    "id": "LLT0qUvYC3rK",
    "outputId": "8e3774e0-79ac-4871-bb92-2a756984ccc7"
   },
   "outputs": [],
   "source": [
    "avg_rating_by_city = df.groupby('City')['Avg ratings'].mean().reset_index(name='Ratings')\n",
    "sns.barplot(x=avg_rating_by_city['City'], y= avg_rating_by_city['Ratings'])\n",
    "plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 500
    },
    "id": "086s_IDgDHiE",
    "outputId": "206cf0be-cc2d-4bed-95c7-5ef450215ede"
   },
   "outputs": [],
   "source": [
    "plt.plot(avg_rating_by_city['City'], avg_rating_by_city['Ratings'])\n",
    "plt.scatter(avg_rating_by_city['City'], avg_rating_by_city['Ratings'],c='red')\n",
    "plt.xticks(rotation=90)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "CMnXoNSJGcJ_",
    "outputId": "3cfd8da2-b661-4560-e55c-98806f4ffbab"
   },
   "outputs": [],
   "source": [
    "#Delivery Time vs Price by City\n",
    "sns.scatterplot(x='Price', y='Delivery time', data=df, hue='City', palette='viridis')\n",
    "plt.title('Delivery Time vs. Price by City')\n",
    "plt.xlabel('Price')\n",
    "plt.ylabel('Delivery Time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 758
    },
    "id": "pqKEEg4tHPeo",
    "outputId": "022bfc8d-ba67-4acf-833c-4bdc98535ca4"
   },
   "outputs": [],
   "source": [
    "# Pairplot\n",
    "sns.pairplot(df[['Price', 'Avg ratings', 'Delivery time']])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "nbfVN9JHIHT9",
    "outputId": "19c2db1f-1b51-4f31-ea73-3b2105ff6ddc"
   },
   "outputs": [],
   "source": [
    "# Word cloud of cuisines\n",
    "from wordcloud import WordCloud\n",
    "all_cuisines = ' '.join(df1['Cuisines'].dropna().unique())\n",
    "wordcloud = WordCloud(width=800, height=400, background_color = 'white').generate(all_cuisines)\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 675
    },
    "id": "8gROU284J77Y",
    "outputId": "7228d542-e6a9-4946-9448-17412a57760b"
   },
   "outputs": [],
   "source": [
    "# Pie chart of restaurant by city\n",
    "city_counts = df['City'].value_counts()\n",
    "city_counts.plot(kind='pie', autopct='%1.1f%%', figsize=(8, 8), startangle=90)\n",
    "plt.title('Restaurant Distribution by City')\n",
    "plt.ylabel('')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "j8fXQiByK0Ai",
    "outputId": "00142b0f-2e7a-4fb1-9308-2380b02342a3"
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "cuisine_price = df1.groupby('Cuisines')['Price'].mean().reset_index()\n",
    "fig = px.bar(cuisine_price.sort_values('Price', ascending=False).head(20),\n",
    "             x='Cuisines', y='Price', title='Average Price by Cuisine',\n",
    "             hover_data=['Price'], color='Price')\n",
    "fig.update_layout(xaxis_tickangle=-45)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "-KFsbptELq3s",
    "outputId": "45229479-5eb6-46db-d18e-a1d2ecdbec3f"
   },
   "outputs": [],
   "source": [
    "restaurant_counts = df.groupby(['City', 'Area']).size().reset_index(name='Count')\n",
    "\n",
    "import plotly.express as px\n",
    "fig = px.treemap(restaurant_counts, path=['City', 'Area'], values='Count',\n",
    "                 title='Restaurant Distribution by City and Area')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "eBDoh1YEMTov",
    "outputId": "11b5a7ff-2498-4894-c5d5-44c48fdfbb63"
   },
   "outputs": [],
   "source": [
    "restaurant_counts = df.groupby(['City', 'Area']).size().reset_index(name='Count')\n",
    "\n",
    "import plotly.express as px\n",
    "fig = px.sunburst(restaurant_counts, path=['City', 'Area'], values='Count',\n",
    "                  title='Sunburst of Restaurants by Location')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "-KTMWSEVNbkw",
    "outputId": "86253279-9bdf-4082-ba24-cb7673beb319"
   },
   "outputs": [],
   "source": [
    "fig = px.box(df1, x='Cuisines', y='Price', points='all')\n",
    "fig.update_layout(title='Price Distribution by Cuisine')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rest_in_Bangalore = (df[df['City'] == 'Bangalore'].groupby(['Area', 'Restaurant'], as_index=False).agg({'Avg ratings': 'mean', 'Total ratings': 'sum'}))\n",
    "rest_in_Bangalore = rest_in_Bangalore.sort_values(['Area', 'Avg ratings'], ascending=[True, False])\n",
    "rest_in_Bangalore = rest_in_Bangalore.groupby('Area').head(3)\n",
    "\n",
    "fig = px.bar(rest_in_Bangalore, \n",
    "             x='Avg ratings', \n",
    "             y='Restaurant', \n",
    "             color='Area',\n",
    "             orientation='h',\n",
    "             hover_data=['Total ratings'],\n",
    "             title=f'Top Restaurants by Area in Bangalore')\n",
    "fig.update_layout(height=800)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "city_list = sorted(df['City'].dropna().unique().tolist())\n",
    "\n",
    "def plot_top_restaurants_by_city(selected_city):\n",
    "    filtered_df = (df[df['City'] == selected_city]\n",
    "                   .groupby(['Area', 'Restaurant'], as_index=False)\n",
    "                   .agg({'Avg ratings': 'mean', 'Total ratings': 'sum'}))\n",
    "\n",
    "    filtered_df = filtered_df.sort_values(['Area', 'Avg ratings'], ascending=[True, False])\n",
    "    filtered_df = filtered_df.groupby('Area').head(3)\n",
    "\n",
    "    fig = px.bar(filtered_df, \n",
    "                 x='Avg ratings', \n",
    "                 y='Restaurant', \n",
    "                 color='Area', \n",
    "                 orientation='h',\n",
    "                 hover_data=['Total ratings'],\n",
    "                 title=f'Top Restaurants by Area in {selected_city}')\n",
    "    fig.update_layout(height=600)\n",
    "    \n",
    "    fig.show()\n",
    "\n",
    "interact(plot_top_restaurants_by_city, selected_city=widgets.Dropdown(options=city_list, description='City:'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = df1.groupby('Cuisines')['Cuisines'].count().reset_index(name='count')\n",
    "# top_30_food = a.sort_values('count', ascending=False).head(30)\n",
    "\n",
    "a = df1['Cuisines'].value_counts().reset_index()\n",
    "a.columns = ['Cuisines', 'count']\n",
    "top_30_food_list = a.head(30)['Cuisines'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Cuisines'] = df1['Cuisines'].apply(lambda x: x if x in top_30_food_list else 'Other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_areas_per_city = df1.groupby('City')['Area'].value_counts().reset_index(name='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_areas = top_areas_per_city.groupby('City')[['City','Area']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_pairs = set([tuple(x) for x in top_10_areas.to_numpy()])\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Area'] = df1.apply(lambda x: x['Area'] if (x['City'], x['Area']) in top_pairs else 'Other',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "cuisine_encoded = pd.DataFrame(\n",
    "    mlb.fit_transform(df1['Cuisines']),\n",
    "    columns=['Cuisine_' + c for c in mlb.classes_],\n",
    "    index=df1.index\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_dummies = pd.get_dummies(df1['Area'], prefix='Area')\n",
    "area_updated = area_dummies.astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded = pd.concat([df1, area_updated, cuisine_encoded], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_encoded = pd.get_dummies(df_encoded['City'], prefix='City')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_updated = city_encoded.astype(int)\n",
    "df_encoded = pd.concat([df_encoded, city_updated], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded = df_encoded.drop(['ID','Area','Restaurant','Food type','Address','Cuisines','City'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = df_encoded.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff['is_highly_rated'] = (dff['Avg ratings'] > 4.0).astype(int)\n",
    "dff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = dff.drop(columns=['is_highly_rated', 'Avg ratings']) \n",
    "y = dff['is_highly_rated'] \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model = LogisticRegression(class_weight='balanced',max_iter=5000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "print(\"Accuracy :\", accuracy_score(y_test, y_pred))          # 0.654 (already known)\n",
    "print(\"Precision:\", precision_score(y_test, y_pred))         # TP / (TP + FP)\n",
    "print(\"Recall   :\", recall_score(y_test, y_pred))            # TP / (TP + FN)\n",
    "print(\"F1 Score :\", f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "rf = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy :\", accuracy_score(y_test, y_pred_rf))          # 0.654 (already known)\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_rf))         # TP / (TP + FP)\n",
    "print(\"Recall   :\", recall_score(y_test, y_pred_rf))            # TP / (TP + FN)\n",
    "print(\"F1 Score :\", f1_score(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature importance\n",
    "\n",
    "feature_importances = rf.feature_importances_\n",
    "features = X.columns\n",
    "importance_df = pd.DataFrame({'Feature': features, 'Importance': feature_importances})\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(data=importance_df.head(20), x='Importance', y='Feature')\n",
    "plt.title('Top 20 Important Features in Random Forest')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_importance = importance_df[importance_df['Importance'] < 0.01]['Feature'].tolist()\n",
    "X_reduced = X.drop(columns=low_importance)\n",
    "\n",
    "X_train_reduced, X_test_reduced, y_train, y_test = train_test_split(X_reduced, y, test_size=0.2, random_state=42)\n",
    "rf.fit(X_train_reduced, y_train)\n",
    "y_pred = rf.predict(X_test_reduced)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"New Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy :\", accuracy_score(y_test, y_pred))          # 0.654 (already known)\n",
    "print(\"Precision:\", precision_score(y_test, y_pred))         # TP / (TP + FP)\n",
    "print(\"Recall   :\", recall_score(y_test, y_pred))            # TP / (TP + FN)\n",
    "print(\"F1 Score :\", f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred)\n",
    "plt.plot(fpr, tpr, label=f'AUC = {auc:.2f}')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(rf, X_reduced, y, cv=5)\n",
    "print(\"Cross-validated accuracy:\", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred)\n",
    "plt.plot(fpr, tpr, label=f'AUC = {auc:.2f}')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "params = {\n",
    "    'objective': 'binary:logistic',  # For binary classification\n",
    "    'eval_metric': 'logloss',        # Evaluation metric for binary classification\n",
    "    'max_depth': 6,                  # Maximum depth of trees\n",
    "    'eta': 0.1,                      # Learning rate\n",
    "    'subsample': 0.8,                # Fraction of samples used for training trees\n",
    "    'colsample_bytree': 0.8,         # Fraction of features used for training trees\n",
    "    'scale_pos_weight': 1,           # Balance the positive class weight (adjust if needed)\n",
    "    'n_jobs': -1                     # Use all CPU cores\n",
    "}\n",
    "\n",
    "model = xgb.train(params, dtrain, num_boost_round=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(dtest)\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)  # Convert probabilities to binary labels\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred_binary)\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "# Print classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_binary))\n",
    "\n",
    "# Confusion matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "important_features = ['Total ratings', 'Price', 'Delivery time', 'Area_Other']  \n",
    "\n",
    "X_train_filtered = X_train[important_features]\n",
    "X_test_filtered = X_test[important_features]\n",
    "\n",
    "model = xgb.XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='logloss',\n",
    "    use_label_encoder=False,\n",
    "    n_estimators=100,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model.fit(X_train_filtered, y_train)\n",
    "y_pred = model.predict(X_test_filtered)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can we classify restaurants as expensive or affordable based on price ranges?\n",
    "\n",
    "dff['is_expensive'] = (dff['Price']>700.0).astype(int)\n",
    "\n",
    "X = dff.drop(columns=['Price','is_expensive'])\n",
    "y = dff['is_expensive']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = LogisticRegression(class_weight='balanced',max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = pd.Series(model.coef_[0], index=X_train.columns)\n",
    "\n",
    "# Sort by absolute value\n",
    "importance_sorted = importance.abs().sort_values(ascending=False)\n",
    "\n",
    "# Display top features\n",
    "print(\"Top important features:\")\n",
    "print(importance_sorted.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = rf.feature_importances_\n",
    "features = X.columns\n",
    "importance_df = pd.DataFrame({'Feature': features, 'Importance': feature_importances})\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(data=importance_df.head(20), x='Importance', y='Feature')\n",
    "plt.title('Top 20 Important Features in Random Forest')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_importance = importance_df[importance_df['Importance'] < 0.01]['Feature'].tolist()\n",
    "X_reduced = X.drop(columns=low_importance)\n",
    "\n",
    "X_train_reduced, X_test_reduced, y_train, y_test = train_test_split(X_reduced, y, test_size=0.2, random_state=42)\n",
    "rf.fit(X_train_reduced, y_train)\n",
    "y_pred = rf.predict(X_test_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred)\n",
    "plt.plot(fpr, tpr, label=f'AUC = {auc:.2f}')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "params = {\n",
    "    'objective': 'binary:logistic',  # For binary classification\n",
    "    'eval_metric': 'logloss',        # Evaluation metric for binary classification\n",
    "    'max_depth': 6,                  # Maximum depth of trees\n",
    "    'eta': 0.1,                      # Learning rate\n",
    "    'subsample': 0.8,                # Fraction of samples used for training trees\n",
    "    'colsample_bytree': 0.8,         # Fraction of features used for training trees\n",
    "    'scale_pos_weight': 1,           # Balance the positive class weight (adjust if needed)\n",
    "    'n_jobs': -1                     # Use all CPU cores\n",
    "}\n",
    "\n",
    "model = xgb.train(params, dtrain, num_boost_round=100)\n",
    "\n",
    "y_pred = model.predict(dtest)\n",
    "y_pred_binary = (y_pred > 0.27).astype(int)  # Convert probabilities to binary labels\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred_binary)\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "# Print classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_binary))\n",
    "\n",
    "# Confusion matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc = roc_auc_score(y_test, y_pred_binary)\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_binary)\n",
    "plt.plot(fpr, tpr, label=f'AUC = {auc:.2f}')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lightgbm\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Create LightGBM model\n",
    "lgb_model = lgb.LGBMClassifier(\n",
    "    objective='binary',  # Binary classification\n",
    "    metric='binary_logloss',  # Evaluation metric\n",
    "    num_leaves=31,  # Number of leaves in one tree\n",
    "    learning_rate=0.1,  # Learning rate\n",
    "    n_estimators=100,  # Number of boosting iterations\n",
    "    subsample=0.8,  # Fraction of data to use for training\n",
    "    colsample_bytree=0.8,  # Fraction of features to use for each tree\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "lgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_lgb = lgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_lgb = accuracy_score(y_test, y_pred_lgb)\n",
    "print(f'Accuracy: {accuracy_lgb * 100:.2f}%')\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_lgb))\n",
    "\n",
    "# Confusion Matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_lgb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "\n",
    "# Train a LightGBM model\n",
    "model = lgb.LGBMClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Get feature importance based on 'gain'\n",
    "importance = model.booster_.feature_importance(importance_type='gain')\n",
    "\n",
    "# Create a DataFrame with feature names and their importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance': importance\n",
    "})\n",
    "\n",
    "# Sort the DataFrame by importance in descending order\n",
    "feature_importance = feature_importance.sort_values(by='importance', ascending=False)\n",
    "\n",
    "# Select top features (e.g., top 10 most important features)\n",
    "top_features = feature_importance.head(10)['feature'].tolist()\n",
    "\n",
    "# Filter the dataset to include only the top features\n",
    "X_train_filtered = X_train[top_features]\n",
    "X_test_filtered = X_test[top_features]\n",
    "\n",
    "# Train a new model with selected features\n",
    "model.fit(X_train_filtered, y_train)\n",
    "\n",
    "# Predict and evaluate the model\n",
    "y_pred = model.predict(X_test_filtered)\n",
    "\n",
    "\n",
    "accuracy_lgb = accuracy_score(y_test, y_pred_lgb)\n",
    "print(f'Accuracy: {accuracy_lgb * 100:.2f}%')\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_lgb))\n",
    "\n",
    "# Confusion Matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_lgb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = dff.drop(columns = ['is_expensive','is_highly_rated'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "X = dff.drop('Avg ratings', axis=1)\n",
    "y = dff['Avg ratings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.3f}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.3f}\")\n",
    "print(f\"R² Score: {r2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = model.feature_importances_\n",
    "features = X.columns\n",
    "\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': features,\n",
    "    'importance': importances\n",
    "})\n",
    "\n",
    "feature_importance = feature_importance.sort_values(by='importance', ascending=False)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.barh(feature_importance['feature'].head(10), feature_importance['importance'].head(10))\n",
    "plt.gca().invert_yaxis()  # Highest importance on top\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.title('Top 10 Feature Importances')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dff[['Total ratings','Delivery time','Price','Area_Other']]\n",
    "y = dff['Avg ratings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.3f}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.3f}\")\n",
    "print(f\"R² Score: {r2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot Actual vs Predicted Ratings\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)  # diagonal line\n",
    "plt.xlabel('Actual Ratings')\n",
    "plt.ylabel('Predicted Ratings')\n",
    "plt.title('Actual vs Predicted Ratings')\n",
    "\n",
    "# Calculate residuals\n",
    "residuals = y_test - y_pred\n",
    "\n",
    "# Plot Residuals\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(y_pred, residuals, alpha=0.5)\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.xlabel('Predicted Ratings')\n",
    "plt.ylabel('Residuals (Actual - Predicted)')\n",
    "plt.title('Residuals Plot')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dff[['Total ratings','Delivery time','Price','Area_Other']]\n",
    "y = dff['Avg ratings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize XGBoost Regressor\n",
    "model = xgb.XGBRegressor(\n",
    "    objective='reg:squarederror',  # regression task\n",
    "    n_estimators=100,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.3f}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.3f}\")\n",
    "print(f\"R² Score: {r2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)  # diagonal line\n",
    "plt.xlabel('Actual Ratings')\n",
    "plt.ylabel('Predicted Ratings')\n",
    "plt.title('Actual vs Predicted Ratings')\n",
    "\n",
    "# Calculate residuals\n",
    "residuals = y_test - y_pred\n",
    "\n",
    "# Plot Residuals\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(y_pred, residuals, alpha=0.5)\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.xlabel('Predicted Ratings')\n",
    "plt.ylabel('Residuals (Actual - Predicted)')\n",
    "plt.title('Residuals Plot')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForest regresssor performed better than XGBoost regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
